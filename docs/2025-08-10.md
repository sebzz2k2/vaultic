# Vaultic Key-Value Store - Project State Documentation
**Date: August 10, 2025**

## Overview

Vaultic is a high-performance, persistent key-value storage engine written in Go. It implements a Log-Structured Merge-Tree (LSM-Tree) inspired architecture with Write-Ahead Logging (WAL) for durability and crash recovery. The project focuses on providing fast write operations through append-only storage and efficient read operations through in-memory indexing.

## Architecture Components

### 1. Storage Engine Foundation

#### Write-Ahead Log (WAL) Implementation
- **Location**: `kv_store/write_ahead_log.go`
- **Purpose**: Primary persistence layer ensuring ACID properties
- **Encoding Format**: Binary encoding with structured layout for optimal storage efficiency

**WAL Entry Format**:
```
4 bytes   | Total length of the entry (including this field)
1 byte    | Encoding format version
1 byte    | Flags for metadata (deleted, compressed, checkpoint, reserved)
4 bytes   | CRC32 checksum (computed over key + value)
8 bytes   | Timestamp (Unix epoch time in milliseconds)
2 bytes   | Key length (in bytes)
4 bytes   | Value length (in bytes)
<key>     | Key data (variable length)
<value>   | Value data (variable length)
```

**Flag System**:
- Bit 0: Deletion flag (0 = active, 1 = deleted)
- Bit 1: Compression flag (0 = uncompressed, 1 = compressed)
- Bit 2: Checkpoint flag (for future use)
- Bits 3-7: Reserved for future features

### 2. Indexing Strategy

#### In-Memory Hash Index
- **Location**: `utils/index_map.go`
- **Implementation**: Go's `sync.Map` for thread-safe concurrent access
- **Index Structure**: Maps keys to `IndexValue` structs containing file offsets

```go
type IndexValue struct {
    Start uint32  // Start byte position in WAL file
    End   uint32  // End byte position in WAL file
}
```

#### Skip List Implementation (In Development)
- **Location**: `kv_store/skip_list.go`
- **Purpose**: Probabilistic data structure for ordered key access
- **Features**: Multi-level linked list with O(log n) search complexity
- **Thread Safety**: Mutex-protected operations
- **Status**: Foundation implemented, integration pending

### 3. Data Flow Architecture

#### Write Path
1. **Command Reception**: TCP server receives SET command via custom protocol
2. **Lexical Analysis**: Command tokenized using regex-based lexer
3. **WAL Encoding**: Key-value pair encoded with metadata (timestamp, CRC, flags)
4. **Append Operation**: Encoded entry appended to WAL file (`vaultic` file)
5. **Index Update**: In-memory hash index updated with new key's file offsets
6. **Response**: Success confirmation sent to client

**Write Path Code Flow**:
```
client.go -> lexer.go -> cmd.go:set() -> write_ahead_log.go:EncodeWAL() -> index_map.go:SetIndexKey()
```

#### Read Path
1. **Command Reception**: TCP server receives GET command
2. **Index Lookup**: Hash index queried for key's file position
3. **File Seek**: Direct file seek to start position using stored offset
4. **Data Retrieval**: Value read from calculated byte range
5. **Response**: Value returned to client (or NIL if not found)

**Read Path Code Flow**:
```
client.go -> lexer.go -> cmd.go:get() -> index_map.go:GetIndexVal() -> File I/O
```

#### Delete Path
1. **Tombstone Creation**: Deleted entry written to WAL with deletion flag set
2. **Index Removal**: Key removed from in-memory index
3. **Logical Deletion**: Original data remains in file but becomes inaccessible

### 4. Server Architecture

#### TCP Server
- **Location**: `server/server.go`, `server/client.go`
- **Protocol**: Custom text-based protocol over TCP
- **Port**: Configurable (default: 5381)
- **Concurrency**: Goroutine per client connection
- **Commands Supported**: GET, SET, DEL, EXISTS, KEYS

#### Command Processing Pipeline
- **Lexer**: `lexer/lexer.go` - Tokenizes input using regex patterns
- **Command Processor**: `cmd/cmd.go` - Routes commands to appropriate handlers
- **Response Handling**: Standardized response format with error handling

### 5. Index Building and Recovery

#### Bootstrap Process
- **Location**: `server/build_indexes.go`
- **Process**: On startup, entire WAL file is scanned to rebuild in-memory index
- **Optimization**: Index building time is measured and logged
- **Recovery**: Handles deleted entries by skipping them during index reconstruction

#### Data Integrity
- **CRC32 Checksums**: Each entry includes checksum for corruption detection
- **Version Control**: Entry format versioning for backward compatibility
- **Timestamp Tracking**: Unix timestamp stored with each entry

### 6. Configuration and Logging

#### Configuration Management
- **Location**: `pkg/config/config.go`
- **Format**: YAML configuration file (`vaultic_config.yaml`)
- **Settings**: Log path, server port, and extensible configuration structure

#### Logging System
- **Framework**: Zerolog for structured logging
- **Levels**: Debug, Info, Warn, Error with configurable output
- **Destinations**: Console and file logging with rotation support

## Current Implementation Status

### âœ… Completed Features
1. **Basic KV Operations**: GET, SET, DEL, EXISTS, KEYS
2. **WAL Implementation**: Complete binary encoding/decoding
3. **TCP Server**: Multi-client support with custom protocol
4. **In-Memory Indexing**: Hash-based index with thread safety
5. **Configuration System**: YAML-based configuration
6. **Logging Infrastructure**: Structured logging with multiple outputs
7. **Index Recovery**: Startup index rebuilding from WAL
8. **Data Integrity**: CRC32 checksums and corruption detection

### ðŸš§ In Progress
1. **Skip List Integration**: Probabilistic data structure implementation
2. **SSTable Support**: File structure defined but not implemented

## Performance Characteristics

### Write Performance
- **Complexity**: O(1) append-only writes
- **Throughput**: Limited by disk I/O and WAL encoding overhead
- **Durability**: Immediate fsync for crash consistency

### Read Performance  
- **Complexity**: O(1) hash index lookup + O(1) file seek
- **Cache**: No read caching currently implemented
- **Bottleneck**: Single file I/O operations

### Memory Usage
- **Index Overhead**: ~24 bytes per key (key string + IndexValue struct)
- **Concurrent Safety**: sync.Map handles concurrent access efficiently
- **Growth**: Linear with number of unique keys

### Benchmark Results (August 10, 2025)

Performance testing conducted with 100 keys using Docker containerized environment with concurrent operations:

| Operation | Keys Processed | Command Send Time | Total Completion Time | Send Ops/sec | Total Ops/sec | Concurrent Workers |
|-----------|----------------|-------------------|----------------------|--------------|---------------|-------------------|
| **SET**   | 100           | 247.8 Âµs          | 3.32 seconds         | 403,481      | 30.15         | 100               |
| **GET**   | 100           | 258.1 Âµs          | 4.15 seconds         | 387,433      | 24.12         | 100               |
| **DELETE** | 100          | 182.9 Âµs          | 3.64 seconds         | 546,729      | 27.47         | 100               |

**Key Observations**:
- **Command Processing**: Extremely fast command parsing and queuing (~200-250 Âµs for 100 operations)
- **I/O Bottleneck**: Significant difference between send rate and completion rate indicates disk I/O as primary bottleneck
- **Write Performance**: SET operations achieve ~30 ops/sec under high concurrency
- **Read Performance**: GET operations slightly slower at ~24 ops/sec due to file seek overhead
- **Delete Performance**: DELETE operations at ~27 ops/sec, including tombstone writes

**Performance Analysis**:
- Network and command processing overhead is minimal (sub-millisecond)
- Storage layer (WAL writes and file I/O) dominates total execution time
- Concurrent access patterns show consistent performance across operation types